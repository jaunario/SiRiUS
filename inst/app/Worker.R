#Title: Worker/Runner
# Tasks:
# 1. Run ORYZA
# 2. Rename output files (op.dat, res.dat)
# 3. Update progress of schema
# TODO: Make this generic. This will be useful for a Distributed computing system

# Checking appropriate working directory ----
library(SiRiUS)

sirius.start()

if (!interactive()) {
  cmd.args <- commandArgs(trailingOnly = TRUE)
  cmd.args <- subset(cmd.args, cmd.args != "--args")
  if (dir.exists(cmd.args[1])) setwd(cmd.args[1]) else stop("Invalid working directory.")
}
#work.dir <- as.character(getwd())
saveRDS("busy", file = "status.rds")


#setwd(work.dir)
# Checking job ----
# tries <- 0
message(basename(cmd.args[1]), ": Getting job details. ")
my.job <- readRDS("job.rds")
#my.job <- readRDS(paste0("schemas/", SCHEMA_NAME, "/", worker, "/job.rds"))
my.job$run.sttime <- Sys.time()
my.job$status <- "running"
saveRDS(my.job, file = "job.rds")
#my.job <- readRDS("job.rds")
# repeat {
#   my.job <- try(readRDS("job.rds"), silent = TRUE)
#   if (class(my.job) != "try-error") break else  Sys.sleep(runif(1))
#   tries <- tries + 1
#   if (tries > 10) {
#     message("No job found. Try again later.")
#     quit(save = "no")
#   }
# }

# Worker preparing ----
load("../schemaconfig.rdata")

# Identifying Soil file ----
# ATM, assumption is Soil files are pre-generated. Possible to have an option to create soilfile as jobs are run
# Can also be generated by schema, but prone to duplication
if (SCHEMA_SOILFILE == "soilgrids.org") {
  #soilres.digits <- ifelse(grepl("6arcmin", SCHEMA_BUILTINS_SUBSET), 2, 7)
  rst.base <- rast("../baseraster.tif")
  #cellFromXY(rst.base, my.job[,c("x", "y")])
  job.soilfile <- sprintf(paste0("%s/%s/%s/soilgrids_cell%g.sol"),
                          SIRIUS_HOME,
                          SOILGRIDS_ORYZADIR,
                          SCHEMA_BUILTINS_SUBSET,
                          my.job$cell[1])
} else {
  job.soilfile <- SCHEMA_SOILFILE
}

if (!file.exists(job.soilfile)) {
  my.job$status[job.available] <- "discard"
} else {
  message(SCHEMA_NAME, ": Working on ", my.job$cell[1], ".")

  # Copying soilfile ----
  file.copy(job.soilfile, paste0("./", SCHEMA_NAME, ".sol"), overwrite = TRUE) # Soil File
  job.soilfile <- paste0("./", SCHEMA_NAME, ".sol")

  # EXPERIMENT File
  if (SCHEMA_WTHSRC == "agera5") {
    SCHEMA_EXPPARAMS <- c(SCHEMA_EXPPARAMS, list(ISTN = my.job$wthcell))
  }
  job.expfile <- oryza.experiment(oryza.dir = ".",
                                  param.list = SCHEMA_EXPPARAMS,
                                  expbase.df = oryzaparams.exp,
                                  filename = paste0(SCHEMA_NAME, ".exp"))


  # Rerun File
  job.rerun <- oryza.rerun(oryza.dir = ".",
                           rerun.param.list = SCHEMA_RERUNPARAMS,
                           param.reference = attr(oryzaparams.exp, "reftable"),
                           filename = paste0(SCHEMA_NAME, ".rer"))

  #job.rerunparams <- buildRerun(rerun.param.list = SCHEMA_NAME, filename = paste0(SCHEMA_NAME, ".rer"))
  #saveRDS(job.rerunparams, file = paste0(schema.dir, "/", worker, "/reruns.rds"))
  ## CONTROL.DAT ----
  oryza.control(oryza.dir = ".", endrun = 1000,
    FILEIT = job.expfile,
    FILEI1 = basename(SCHEMA_VARIETYFILE),
    FILEI2 = job.soilfile,
    FILEIR = job.rerun,
    SOILKILL = ifelse(SCHEMA_CONTSIM, "NO", "YES")
  )

  # Running ORYZA ----
  worker.outcome <- system2("./ORYZA3", wait = TRUE, stdout = TRUE)

  if (sum(grepl("Fatal execution error", worker.outcome)) > 0) {
    my.job$status <- "error"
  } else {

    # opdat.newname <- paste0(SCHEMA_INTERMDIR, "/", "cell", my.job$cell[1], "_OP.dat")
    # if (exists("SCHEMA_MAPVARS_RESDAT")) resdat.newname <- sprintf("../out/daily/cell%06g_res.dat", my.job$cell[1])
    dat.op <- readOPDAT("op.dat", selected.fields = SCHEMA_MAPVARS_OPDAT, cell = my.job$cell[1])
    dat.op <- split(dat.op, sprintf(paste0("RUN%0", max(nchar(dat.op$RUNNUM)), "g"), dat.op$RUNNUM))
    #message("Copying op.dat to ", opdat.newname)
    files.cellyear <-  paste0(SCHEMA_INTERMDIR, "/by_runs/", names(dat.op), "/", names(dat.op), "_cell", my.job$cell[1], ".rds")
    #file.copy("OP.dat", opdat.newname)
    success <- lapply(as.list(dirname(files.cellyear)), force.directories, recursive = TRUE)
    rm(success)

    success <- mapply(saveRDS, dat.op, as.list(files.cellyear), USE.NAMES = FALSE)
    rm(success)

    # Moving output to schema output folder ----
    if (exists("SCHEMA_MAPVARS_RESDAT") && length(SCHEMA_MAPVARS_RESDAT) > 0) {
      dat.res <- readRESDAT("res.dat", cell = my.job$cell[1], selected.fields = SCHEMA_MAPVARS_RESDAT, verbose = FALSE)
      rownames(dat.res) <- NULL
      dat.res <- split(dat.res, format(dat.res$date, "P%Y_%m"))

      # Prepating filenames ----
      files.cellyear <-  paste0(SCHEMA_INTERMDIR, "/daily/", substr("P", "", names(dat.res)), "/", names(dat.res), "_cell", my.job$cell[1], ".rds")

      # Creating container direcories ----
      success <- lapply(as.list(dirname(files.cellyear)), force.directories, recursive = TRUE)
      rm(success)
      #dat.res <- split(dat.res, dat.res$date)
      success <- mapply(saveRDS, dat.res, as.list(files.cellyear), USE.NAMES = FALSE)
      rm(success)

      #message("Copying res.dat to ", resdat.newname, appendLF = TRUE)
      #file.copy("res.dat", resdat.newname)
    }
    my.job$status <- "done"
  }
}

my.job$run.entime <- Sys.time()
#saveRDS(my.job, "job.rds")

if (file.exists("prevjobs.rds")) {
  dat.prevjobs <- readRDS("prevjobs.rds")
  dat.prevjobs <- rbind(dat.prevjobs, my.job)
} else {
  dat.prevjobs <- my.job
}
saveRDS(dat.prevjobs, "prevjobs.rds")
file.remove("job.rds")

# Sleep for a random amount of time (milliseconds) to allow controller create new workers, and more simultaneous jobs
# Sys.sleep(runif(1))

saveRDS("ready", file = "status.rds")
# Done. ----
