#Title: Worker/Runner
# Tasks:
# 1. Run ORYZA
# 2. Rename output files (op.dat, res.dat)
# 3. Update progress of schema
# TODO: Make this generic. This will be useful for a Distributed computing system

# Checking appropriate working directory ----
if (!interactive()) {
  cmd.args <- commandArgs(trailingOnly = TRUE)
  cmd.args <- subset(cmd.args, cmd.args != "--args")

  if (dir.exists(cmd.args[1])) setwd(cmd.args[1]) else stop("Invalid working directory.")
}

# Checking job ----
tries <- 0
message("Getting job details. ")
repeat {
  my.job <- try(readRDS("job.rds"), silent = TRUE)
  if (class(my.job) != "try-error") break else  Sys.sleep(runif(1))
  tries <- tries + 1
  if (tries > 10) {
    message("No job found. Try again later.")
    quit(save = "no")
  }
}

# Worker preparing ----
saveRDS("busy", file = "status.rds")
load("../config.rdata")

message(SCHEMA_NAME, ": Working on ", my.job$cell[1], ".")
opdat.newname <- sprintf("../out/seasonal/cell%06g_OP.dat", my.job$cell[1])
resdat.newname <- sprintf("../out/daily/cell%06g_res.dat", my.job$cell[1])

# Identifying Soil file ----
# ATM, assumption is Soil files are pre-generated. Possible to have an option to create soilfile as jobs are run
# Can also be generated by schema, but prone to duplication
if (SCHEMA_SOILSRC == "soilgrids.org") {
  #soilres.digits <- ifelse(grepl("6arcmin", SCHEMA_BUILTINS_SUBSET), 2, 7)
  rst.base <- rast("baseraster.tif")
  #cellFromXY(rst.base, my.job[,c("x", "y")])
  job.soilfile <- sprintf(paste0("%s/%s/%s/soilgrids_cell%g.sol"),
                          SIRIUS_HOME,
                          SOILGRIDS_ORYZADIR,
                          SCHEMA_BUILTINS_SUBSET,
                          my.job$cell[1])
} else {
  job.soilfile <- SCHEMA_SOILFILE
}

if (!file.exists(job.soilfile)) {
  my.job$status[job.available] <- "discard"
  saveRDS(my.job, file = "job.rds")
} else {
  # Copying soilfile ----
  file.copy(job.soilfile, paste0("./", SCHEMA_NAME, ".sol"), overwrite = TRUE) # Soil File

  # Running ORYZA ----
  worker.outcome <- system2("./ORYZA3", wait = TRUE, stdout = TRUE)

  if (sum(grepl("Fatal execution error", worker.outcome)) > 0) {
    my.job$status <- "error"
    my.job$run.entime <- Sys.time()
    saveRDS(my.job, "job.rds")
  } else {
    my.job$status <- "done"
    my.job$run.entime <- Sys.time()

    # Moving output to schema output folder ----
    if (SCHEMA_ANIMATE) {
      dat.res <- resdatToDF("res.dat", cell = my.job$cell[1], selected.fields = SCHEMA_MAPFIELDS, verbose = FALSE)
      rownames(dat.res) <- NULL

      # Standardizing values ----
      for (j in seq_along(SCHEMA_MAPFIELDS)) {
        cellvar_values <- switch(SCHEMA_MAPFIELDS[j],
                                 CO2C = as.integer(round(dat.res[, SCHEMA_MAPFIELDS[j]] * 44 * 1000 / 12, 0)),
                                 CH4C = as.integer(round(dat.res[, SCHEMA_MAPFIELDS[j]] * 16 * 1000 / 12, 0)),
                                 N2ON = as.integer(round(dat.res[, SCHEMA_MAPFIELDS[j]] * 44 * 1000 / 28, 0)),
                                 WRR14 = as.integer(round(dat.res[, SCHEMA_MAPFIELDS[j]] * 1000, 0)),
                                 dat.res[, SCHEMA_MAPFIELDS[j]])

        dat.res[, SCHEMA_MAPFIELDS[j]] <- cellvar_values
        rm(cellvar_values)
      }
      dat.res <- split(dat.res, format(dat.res$date, "P%Y_%m"))

      # Prepating filenames ----
      files.cellyear <-  paste0(SPEED_STORAGE, "/", SCHEMA_NAME, "/out/", substr(names(dat.res), 2, 5), "/", names(dat.res), "_cell", my.job$cell[1], ".rds")

      # Creating container direcories ----
      success <- lapply(as.list(dirname(files.cellyear)), manipulateR::force.directories, recursive = TRUE)
      rm(success)
      #dat.res <- split(dat.res, dat.res$date)
      success <- mapply(saveRDS, dat.res, as.list(files.cellyear), USE.NAMES = FALSE)
      rm(success)

      message("Copying res.dat to ", resdat.newname, appendLF = TRUE)
      file.copy("res.dat", resdat.newname)
    }

    message("Copying op.dat to ", opdat.newname)
    file.copy("OP.dat", opdat.newname)
  }

}

if (file.exists("prevjobs.rds")) {
  dat.prevjobs <- readRDS("prevjobs.rds")
  dat.prevjobs <- rbind(dat.prevjobs, my.job)
  saveRDS(dat.prevjobs, "prevjobs.rds")
} else {
  dat.prevjobs <- my.job
  saveRDS(dat.prevjobs, "prevjobs.rds")
}

file.remove("job.rds")

# Sleep for a random amount of time (milliseconds) to allow controller create new workers, and more simultaneous jobs
# Sys.sleep(runif(1))
# Done. ----
saveRDS("ready", file = "status.rds")
